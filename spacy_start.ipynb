{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://spacy.io \n",
    "* https://github.com/astanin/python-tabulate –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ tabulate –¥–ª—è —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Å–ø–∏—Å–∫–æ–≤\n",
    "* https://github.com/Textualize/rich –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –†–∏—á –¥–ª—è –∫—Ä–∞—Å–∏–≤–∏—à–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å —Å –∫—É—á–µ–π –ø–ª—é—à–µ–∫ (–µ—Å—Ç—å –≥–∞–π–¥ –Ω–∞ —Ä—É—Å—Å–∫–æ–º)  \n",
    "\n",
    "–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –º—ã –±—É–¥–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π Dostoevsky.  \n",
    "https://egorovegor.ru/analiz-tonalnosti-s-python-i-dostoevsky/ - –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç—É—Ç—å  \n",
    "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω—É–∂–Ω–æ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å FastTextSocialNetworkModel –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å RegexTokenizer.\n",
    "\n",
    "–í–∫—Ä–∞—Ç—Ü–µ –æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –º–æ–∂–Ω–æ —á–∏—Ç–Ω—É—Ç—å —Ç—É—Ç üëá.  \n",
    "–ù–æ —Å—Ç–∞—Ç—å—è —Å—Ç–∞—Ä–∞—è, –∫–æ–¥ –æ—Ç—Ç—É–¥–∞ –ª—É—á—à–µ –Ω–µ —Ç—ã—Ä–∏—Ç—å, –∑–∞ 4 –≥–æ–¥–∞ —á—Ç–æ-—Ç–æ —É–ª—É—á—à–∏–ª–∏-–ø–µ—Ä–µ–ø–∏—Å–∞–ª–∏-–∏—Å–ø—Ä–∞–≤–∏–ª–∏-–ø–µ—Ä–µ–¥–µ–ª–∞–ª–∏.  \n",
    "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤—Å–µ–≥–¥–∞ –Ω–∞ –æ—Ñ—Ñ.—Å–∞–π—Ç–µ  \n",
    "* https://habr.com/ru/articles/531940/\n",
    "* https://habr.com/ru/articles/504680/\n",
    "\n",
    "–ü–µ—Ä–≤—ã–π –±–ª–æ–∫ üëá - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑, –ø–æ—Ç–æ–º –∑–∞–∫–æ–º–µ–Ω—Ç–∏—Ç—å, —á—Ç–æ–± –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–ª, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ª–∏ –∏–ª–∏ –Ω–µ  \n",
    "–ö—Å—Ç–∞—Ç–∏, –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ —ç–º–æ–¥–∑–µ–π –º–æ–∂–Ω–æ –Ω–∞–∂–∞—Ç—å \"–í–∏–Ω + –Æ\", –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –¥–∏–∞–ª–æ–≥ ‚ú®üéâ  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spacy\n",
    "# %pip install tabulate\n",
    "# %pip install rich         # –±–∏–±–ª–∏–æ—Ç–µ–∫–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–π —Ç–µ–∫—Å—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ä–º–∏–Ω–∞–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢—É—Ç –ø–æ–¥–∫–ª—é—á–∞–µ–º:\n",
    "- –≤—Å—è–∫–∏–µ —Å–ø–µ–π—Å–∏-—à—Ç—É–∫–∏\n",
    "- –¢–∞–±—É–ª–µ–π—Ç –∏ –†–∏—á –ø—Ä–∏–±–ª—É–¥—ã\n",
    "- —Å–æ–∑–¥–∞–µ–º –†–∏—á-–∫–æ–Ω—Å–æ–ª—å–∫—É\n",
    "- —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ù–õ–ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "\n",
    "–Ø –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª –≤—ã–≤–æ–¥ **—Å—Ç–æ–ø-—Å–ª–æ–≤** (–æ–Ω–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ `nlp.Defaults.stop_words`)  \n",
    "–ù–µ –∑–∞–±—ã–≤–∞–µ–º, —á—Ç–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –Ω–∞–¥–æ –∫–∞—á–Ω—É—Ç—å –º–æ–¥–µ–ª—å `python -m spacy download ru_core_news_sm` (https://spacy.io/usage/models)  \n",
    "–ò –ø—Ä–∏–º–µ—Ä–æ–≤ (`sentences[0]`) (–±–µ—Ä–µ–º –æ—Ç—Å—é–¥–∞ - `from spacy.lang.ru.examples import sentences`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "from spacy.lang.ru.examples import sentences\n",
    "from spacy.lang.ru import Russian\n",
    "\n",
    "from tabulate import tabulate       # —à—Ç—É–∫–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Å–ø–∏—Å–∫–æ–≤ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "from rich.console import Console    # –î–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–¥ —Ç–µ—Ä–º–∏–Ω–∞–ª–æ–º\n",
    "from rich import inspect            # —É–∫—Ä–∞—Å–∏—Ç—å –ª—é–±–æ–π Python –æ–±—ä–µ–∫—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä –∫–ª–∞—Å—Å, –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏—é.\n",
    "from rich.table import Table        # –†–∏—á-—Ç–∞–±–ª–∏—Ü–∞\n",
    "\n",
    "console = Console()     # —Å–æ–∑–¥–∞–µ–º –†–∏—á-–∫–æ–Ω—Å–æ–ª—å\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_md\")\n",
    "# print (nlp.Defaults.stop_words)\n",
    "# print (sentences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/visualizers - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∑–∞–≥–æ–Ω—è–µ–º –≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç –∏ –ø–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç doc\n",
    "doc = nlp(\n",
    "    \"–ú–∞—à–∏–Ω—ã –ø–æ–¥–æ–±–Ω—ã–µ –ë—É—Ö–∞–Ω–∫–µ —Å–∫–æ—Ä–æ —Å–æ–π–¥—É—Ç —Å –∫–æ–Ω–≤–µ–µ—Ä–∞. \" \n",
    "    \"–ù–æ–≤—ã–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å –õ–∞–¥–∞ –æ—Ç —Ñ–∏—Ä–º—ã –ê–≤—Ç–æ–≤–∞–∑ –ø–æ—Å—Ç—É–ø–∏—Ç –≤ –ø—Ä–æ–¥–∞–∂—É —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é - –∑–∞—è–≤–∏–ª –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –°–∏–¥–æ—Ä–æ–≤. –û–Ω –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å 3 –º–∏–ª–ª–∏–æ–Ω–∞ —Ä—É–±–ª–µ–π. \"\n",
    "    \"–¢—ã—Ü —Ç—ã—Ä—ã—Ü\")\n",
    "\n",
    "# —Ç–∞–∫ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∞ —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ –æ–±—ä–µ–∫—Ç–∞ doc\n",
    "# inspect(doc, methods=True)  \n",
    "\n",
    "# –≤—ã–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –†–∏—á-–∫–æ–Ω—Å–æ–ª—å\n",
    "console.print (\":pile_of_poo:\")\n",
    "console.print (doc.text)\n",
    "\n",
    "# –º–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∫–∞–∫ —Å—Ä–µ–∑\n",
    "# print (doc[0:3])\n",
    "\n",
    "\n",
    "# print (doc[0].text)\n",
    "\n",
    "# –ø–µ—Ä–≤–æ–æ–±—Ä–∞–∑–Ω–∞—è —Ñ–æ—Ä–º–∞ —Å–ª–æ–≤–∞\n",
    "# print (doc[0].lemma_)\n",
    "\n",
    "# —Å—Ç–æ–ø-—Å–ª–æ–≤–æ –∏–ª–∏ –Ω–µ\n",
    "# print (doc[0].is_stop)\n",
    "\n",
    "# —Å –ø–æ–º–æ—â—å—é –¥–∏—Å–ø–ª–µ–π—Å–∏ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ç–µ–∫—Å—Ç–∞\n",
    "# displacy.render(doc, style='dep', jupyter=True)\n",
    "\n",
    "# serve - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á–µ—Ä–µ–∑ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä 127.0.0.1:5000\n",
    "# displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é tabulate (–¥–µ–ª–∞–µ—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –∫—Ä–∞—Å–∏–≤—É—é —Ç–∞–±–ª–∏—á–∫—É)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_table = []\n",
    "for token in doc:\n",
    "    token_table.append ([token.text, token.pos_, token.dep_, token.lemma_])\n",
    "console.print (tabulate(token_table, headers= [\"–¢–µ–∫—Å—Ç\", \"–ß–∞—Å—Ç—å —Ä–µ—á–∏\", \"–ß–æ—Ç –µ—â–µ\", \"–õ–µ–º–º–∞\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢—É—Ç –≤—ã–≤–æ–∂—É —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–æ–Ω–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ `doc.ents`) —Å –ø–æ–º–æ—â—å—é –†–∏—á–µ–≤—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table(header_style=\"bold red\")\n",
    "table.add_column(\"–¢–µ–∫—Å—Ç\")\n",
    "table.add_column(\"Label\")\n",
    "table.add_column(\"–ü–æ—è—Å–Ω–µ–Ω–∏–µ\", justify= \"right\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "\n",
    "    table.add_row(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "    # print(ent.text, ent.label_, spacy.explain(ent.label_))\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä, –∫–∞–∫ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞–π—Ç–∏ —á–∏—Å–ª–æ `token.like_num` –∏ –µ—Å–ª–∏ –∑–∞ –Ω–∏–º —Å–ª–µ–¥—É–µ—Ç —Ç–æ–∫–µ–Ω-\"–ü–†–û–¶–ï–ù–¢\" - –≤—ã–≤–µ—Å—Ç–∏ —ç—Ç–æ —á–∏—Å–ª–æ.  \n",
    "–£ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –µ—Å—Ç—å –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä `token.i`. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, —Å–ª–µ–¥—É—é—â–∏–π –∑–∞ –Ω–∏–º –±—É–¥–µ—Ç `token.i+1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp (\"–ë—É—Ö–∞–Ω–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç 4% –æ—Ç –∫–æ–ª-–≤–∞ –º–∞—à–∏–Ω \"\n",
    "            \"–í –Ω–∞—à–µ–º —Å–∞–ª–æ–Ω–µ 20% –º–∞—à–∏–Ω - –ë—É—Ö–∞–Ω–∫–∏\")\n",
    "print(doc1[8])\n",
    "\n",
    "for token in doc1:\n",
    "    if token.like_num:\n",
    "        nt = doc1[token.i + 1]\n",
    "        if nt.text == \"%\":\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spacy.io/usage/rule-based-matching - c–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–∞–≤–∏–ª  \n",
    "https://demos.explosion.ai/matcher - –º–æ–∂–Ω–æ –ø–æ—Ç–µ—Å—Ç–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –æ–Ω–ª–∞–π–Ω, –Ω–æ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–∞–º –Ω–µ—Ç ü§∑‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ø—Ä–∏–≤–µ—Ç, –º–∏—Ä? –ø—Ä–∏–≤–µ—Ç, –º–∏—Ä 111\")\n",
    "#–≤—Ä—É–±–∞–µ–º –º—ç—Ç—á–µ—Ä, –ø–æ–¥–∫–ª—é—á–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫—É\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —à–∞–±–ª–æ–Ω –∏–∑ 3 —Ç–æ–∫–µ–Ω–æ–≤\n",
    "pattern = [{\"LOWER\": \"–ø—Ä–∏–≤–µ—Ç\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"–º–∏—Ä\"}]\n",
    "#pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "#pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –º—ç—Ç—á–µ—Ä\n",
    "matcher.add(\"HW\", [pattern])\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ —Ç–µ–∫—Å—Ç—É\n",
    "matches = matcher(doc2)\n",
    "console.print (matches)\n",
    "console.print(\"–°–æ–≤–ø–∞–¥–µ–Ω–∏—è:\", [doc2[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤. –≠—Ç–æ –∫—Ä–∞—Ç–∫–∞—è –∑–∞–ø–∏—Å—å, –ø–∏—Ç–æ–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ç–∞–∫–∏–µ —Ñ–∏—à–µ—á–∫–∏.  \n",
    "–ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Ç–æ–∫–µ–Ω–∞–º –≤ doc1 –∏ –µ—Å–ª–∏ —ç—Ç–æ—Ç —Ç–æ–∫–µ–Ω –Ω–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–æ - –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –ª–µ–º–º—É –≤ —Å–ø–∏—Å–æ–∫.  \n",
    "–í –±–ª–æ–∫–µ –Ω–∏–∂–µ - —Ç–∞ –∂–µ –æ–ø–µ—Ä–∞—Ü–∏—è, –Ω–æ –≤ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω–æ–º –≤–∏–¥–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_text = []\n",
    "\n",
    "clear_text = [token.lemma_ for token in doc1 if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_text = []\n",
    "\n",
    "for token in doc1:\n",
    "    if not token.is_stop:\n",
    "        clear_text.append (token.lemma_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
